{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "mbert_model = AutoModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.dataloader import DataModule\n",
    "from model.model import FineTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataModule(\n",
    "    train_path='../../data/train_new.csv',\n",
    "    val_path='../../data/val_new.csv',\n",
    "    tokenizer_name_or_path='bert-base-multilingual-cased',\n",
    "    train_batch_size=2,\n",
    "    val_batch_size=2,\n",
    "    stage='fit'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(stage='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, batch in enumerate(dm.val_dataloader()):\n",
    "    sample_batch = batch\n",
    "    if id > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 18939, 60965,  ...,     0,     0,     0],\n",
       "         [  101, 10124, 10371,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1574/1043999892.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_model' is not defined"
     ]
    }
   ],
   "source": [
    "output = bert_model(sample_batch['input_ids'], attention_mask=sample_batch['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28261/498666699.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = FineTuner(\n",
    "    model_name_or_path='bert-base-multilingual-cased',\n",
    "    learning_rate=2e-4,\n",
    "    tokenizer=dm.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7449, grad_fn=<BinaryCrossEntropyBackward>),\n",
       " tensor([[0.5715, 0.4379, 0.5243, 0.4908, 0.4935, 0.3759, 0.6350, 0.4501, 0.5480,\n",
       "          0.5087],\n",
       "         [0.5274, 0.4450, 0.5273, 0.5123, 0.5386, 0.4373, 0.5112, 0.5497, 0.5396,\n",
       "          0.4467]], grad_fn=<SigmoidBackward>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model._step(sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/shivprasad.sagare/miniconda3/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py:416: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  \"You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet.\"\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for id, batch in enumerate(dm.val_dataloader()):\n",
    "    outputs.append(bert_model.validation_step(batch, id))\n",
    "    if id > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': tensor(0.7009, grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  'outputs': tensor([[0.5228, 0.5269, 0.4807, 0.4557, 0.5121, 0.4515, 0.4721, 0.4995, 0.5145,\n",
       "           0.4949],\n",
       "          [0.5338, 0.5524, 0.4871, 0.4286, 0.5025, 0.4551, 0.4825, 0.4923, 0.5098,\n",
       "           0.4970]], grad_fn=<SigmoidBackward>),\n",
       "  'labels': tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])},\n",
       " {'val_loss': tensor(0.6888, grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  'outputs': tensor([[0.5319, 0.5664, 0.4816, 0.4369, 0.4706, 0.4282, 0.4651, 0.5074, 0.5291,\n",
       "           0.4790],\n",
       "          [0.5418, 0.5513, 0.4766, 0.4247, 0.4869, 0.3938, 0.4699, 0.4951, 0.5338,\n",
       "           0.4888]], grad_fn=<SigmoidBackward>),\n",
       "  'labels': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])},\n",
       " {'val_loss': tensor(0.6723, grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  'outputs': tensor([[0.5473, 0.5553, 0.4651, 0.4227, 0.4888, 0.4017, 0.4662, 0.4958, 0.5389,\n",
       "           0.4796],\n",
       "          [0.5309, 0.5312, 0.4615, 0.4256, 0.5109, 0.3853, 0.4703, 0.4932, 0.5206,\n",
       "           0.4872]], grad_fn=<SigmoidBackward>),\n",
       "  'labels': tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])},\n",
       " {'val_loss': tensor(0.6755, grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  'outputs': tensor([[0.5440, 0.5308, 0.4778, 0.4359, 0.5048, 0.4351, 0.4688, 0.5144, 0.5189,\n",
       "           0.5054],\n",
       "          [0.5266, 0.5445, 0.4820, 0.4428, 0.4940, 0.4229, 0.4702, 0.4920, 0.5295,\n",
       "           0.4817]], grad_fn=<SigmoidBackward>),\n",
       "  'labels': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])},\n",
       " {'val_loss': tensor(0.6870, grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  'outputs': tensor([[0.5363, 0.5491, 0.4844, 0.4265, 0.5041, 0.4063, 0.4815, 0.5024, 0.5277,\n",
       "           0.4715],\n",
       "          [0.5190, 0.5838, 0.4881, 0.4497, 0.5118, 0.4277, 0.4867, 0.4804, 0.5055,\n",
       "           0.4970]], grad_fn=<SigmoidBackward>),\n",
       "  'labels': tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])},\n",
       " {'val_loss': tensor(0.6970, grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  'outputs': tensor([[0.5365, 0.5517, 0.4886, 0.4231, 0.4815, 0.4314, 0.4908, 0.5035, 0.5204,\n",
       "           0.4803],\n",
       "          [0.5311, 0.5500, 0.4788, 0.4390, 0.4808, 0.4250, 0.4728, 0.5039, 0.5302,\n",
       "           0.4963]], grad_fn=<SigmoidBackward>),\n",
       "  'labels': tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])},\n",
       " {'val_loss': tensor(0.6970, grad_fn=<BinaryCrossEntropyBackward>),\n",
       "  'outputs': tensor([[0.4721, 0.6328, 0.4732, 0.3392, 0.5536, 0.5649, 0.4823, 0.4952, 0.5142,\n",
       "           0.5341],\n",
       "          [0.5185, 0.5598, 0.4663, 0.4307, 0.5158, 0.4089, 0.4674, 0.4872, 0.5077,\n",
       "           0.4880]], grad_fn=<SigmoidBackward>),\n",
       "  'labels': tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_epoch_end(outputs):\n",
    "        # calculate metric score here\n",
    "        predictions = [x['outputs'] for x in outputs]\n",
    "        print(predictions)\n",
    "        predictions = np.array([np.argmax(preds.detach().cpu().numpy(), axis=1) for preds in predictions]).flatten()\n",
    "        labels = [x['labels'] for x in outputs]\n",
    "        print(labels)\n",
    "        labels = np.array([np.argmax(labels.detach().cpu().numpy(), axis=1) for labels in labels]).flatten()\n",
    "        print(predictions)\n",
    "        print(labels)\n",
    "        if 0 in labels:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = f1_score(labels, predictions, average='weighted')\n",
    "        return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34596/2843956923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f1' is not defined"
     ]
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [x['outputs'] for x in outputs]\n",
    "predictions = np.array([np.argmax(preds.detach().numpy(), axis=1) for preds in predictions]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [x['labels'] for x in outputs]\n",
    "labels = np.array([np.argmax(labels.detach().numpy(), axis=1) for labels in labels]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 8, 8, 5, 7, 6, 6, 6, 7, 3, 7, 7, 4, 7, 7, 6, 8, 4, 6, 5, 6, 3,\n",
       "       6, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(labels, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score([1, 3, 1], [1, 2, 1], average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/shivprasad.sagare/miniconda3/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py:416: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n",
      "  \"You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet.\"\n"
     ]
    }
   ],
   "source": [
    "bert_model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd0d782713032c239be331c9ea6d054a3c886f04ae6d19082ca5dd54216e8bc8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
